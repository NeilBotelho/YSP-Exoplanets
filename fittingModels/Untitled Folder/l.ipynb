{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "def hideCode():\n",
    "    HTML('''<script>\n",
    "    code_show=true; \n",
    "    function code_toggle() {\n",
    "     if (code_show){\n",
    "     $('div.input').hide();\n",
    "     } else {\n",
    "     $('div.input').show();\n",
    "     }\n",
    "     code_show = !code_show\n",
    "    } \n",
    "    $( document ).ready(code_toggle);\n",
    "    </script>\n",
    "    <form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 5502k  100 5502k    0     0   926k      0  0:00:05  0:00:05 --:--:-- 1318k\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/NeilBotelho/YSP-Exoplanets/master/exoplanets.csv >ex.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "hideCode()\n",
    "import pandas as pd\n",
    "import random as r\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "preprocessed=pd.read_csv(\"../PreprocessedDataset.csv\")\n",
    "habitableRows=list(preprocessed.rowid[preprocessed.habitable==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData():\n",
    "    #List of columns to be used for training\n",
    "    #it will be all columns in preprocessed except for \"habitable\" and \"rowid\"\n",
    "    trainCols=[x for x in preprocessed.columns if x not in ['habitable','rowid']]\n",
    "    validate=[]\n",
    "    Hcopy=habitableRows.copy()\n",
    "    #numHidden sets the number of habitable planets to use for validation of the model\n",
    "    numHidden=round(len(Hcopy)/2)\n",
    "\n",
    "    #Randomly select habitable exoplanets and \n",
    "    #add their row_id to validation set \n",
    "    print(\"Hiding \",numHidden,\" habitable(\",end=\"\")\n",
    "    for i in range(numHidden): \n",
    "        randNum=r.randint(0,len(Hcopy)-1)  \n",
    "        validate.append(Hcopy[randNum])\n",
    "        print(Hcopy[randNum],end=\",\")\n",
    "        del Hcopy[randNum]\n",
    "    print(\"\\b )\")\n",
    "\n",
    "    #Add row_id of non-habitable planets to the validation set till its length becomes 200\n",
    "    while len(validate)<200:\n",
    "        temp=r.randint(0,len(preprocessed)-1)\n",
    "        if temp not in habitableRows and temp not in validate:\n",
    "            validate.append(temp)\n",
    "\n",
    "    #Take all columns of the planets whose row_id is in \"validate\" variable(in the validation set) and\n",
    "    #store it in \"validate\" variable\n",
    "    validate=preprocessed[preprocessed.rowid.isin(validate)]\n",
    "\n",
    "    #Store the planets that are not in the validation set in the training set\n",
    "    trainingSet=preprocessed[~preprocessed.rowid.isin(validate.rowid)]\n",
    "\n",
    "    #Store the training features in X and target feature(habitable or not) in y \n",
    "    X=trainingSet[trainCols]\n",
    "    y=trainingSet.habitable\n",
    "\n",
    "    #the SMOTE library mutates existing data to creating more data\n",
    "    #Here we use SMOTE to increase the number of habitable planets in the training and validation data\n",
    "    smote = SMOTE(ratio='minority')\n",
    "    X_sm, y_sm = smote.fit_sample(X, y)\n",
    "    trainX, testX,trainY,testY=train_test_split(X_sm,y_sm)\n",
    "    validateX,validateY=smote.fit_sample(validate[trainCols],validate.habitable)\n",
    "    return trainX, testX,trainY,testY,validateX,validateY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Random Seed on model\n",
    " Does changing the random seed during training but keeping the same dataset substantially change the outcome for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  24  habitable(128,2189,2316,2547,986,117,1424,1845,3115,3606,2097,2441,1205,3962,2031,153,2882,152,3743,1147,2902,2156,2883,2155,\b )\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "Bestscores=[0,0]\n",
    "trainX, testX,trainY,testY,validateX,validateY=prepareData()\n",
    "\n",
    "max_depth=[3,5,7,10]\n",
    "learning_rate=[1,0.1,0.01,0.001]\n",
    "n_estimators=[10,50,100,150,200]\n",
    "early_stopping_rounds=[3,5,10,20]\n",
    "booster=[\"gbtree\",\"dart\"]\n",
    "n_jobs=-1\n",
    "loss_function=['Logloss','CrossEntropy','MultiClass', 'MultiClassOneVsAll' ]\n",
    "\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    Bestscores=[0,0]\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    for l in learning_rate:\n",
    "        for n in n_estimators:\n",
    "            for b in [0,1]:\n",
    "                for m in max_depth:\n",
    "                    for early in early_stopping_rounds:\n",
    "                        model=XGBClassifier(verbosity=0,max_depth=m,learning_rate=l,booster=booster[int(b)])\n",
    "                        model.fit(trainX,trainY,eval_set=[(testX,testY)],early_stopping_rounds=early,verbose=False)\n",
    "                        y_preds=model.predict(validateX)\n",
    "                        currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                        if(currScore>Bestscores[0]):\n",
    "                            Bestscores[0]=currScore\n",
    "                            Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of changing random seed when preparing data on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "Hiding  24  habitable(3233,163,117,2031,2014,1845,1137,703,3716,153,3922,2883,130,128,1205,2156,2223,151,2542,1604,3133,3115,3741,2880,\b )\n",
      "BEST SCORE: 0.9772727272727273\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "Hiding  24  habitable(2014,130,3962,2882,2547,2189,2503,128,1137,1227,2883,1604,2541,3233,114,152,3132,3742,117,1424,163,1205,1845,2542,\b )\n",
      "BEST SCORE: 0.9346590909090909\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "Hiding  24  habitable(2902,1147,151,2014,2547,2135,3962,2223,1205,3233,1424,1227,114,2156,1845,986,128,3744,2441,2541,117,3741,2129,3115,\b )\n",
      "BEST SCORE: 0.7897727272727273\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "Hiding  24  habitable(151,3133,1205,2156,3962,3115,3742,2223,2129,3744,986,2316,2014,2547,1147,117,2097,3741,3132,114,2155,152,3716,1845,\b )\n",
      "BEST SCORE: 0.9630681818181819\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "Hiding  24  habitable(986,2547,2882,2031,1205,1147,2097,1227,128,2902,3233,3962,163,2021,2441,1424,1137,3744,130,2883,2135,3742,2156,3743,\b )\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "Bestscores=[0,0]\n",
    "forCalc=[]\n",
    "max_depth=[3,5,7,10]\n",
    "learning_rate=[1,0.1,0.01,0.001]\n",
    "n_estimators=[10,50,100,150,200]\n",
    "early_stopping_rounds=[3,5,10,20]\n",
    "booster=[\"gbtree\",\"dart\"]\n",
    "n_jobs=-1\n",
    "loss_function=['Logloss','CrossEntropy','MultiClass', 'MultiClassOneVsAll' ]\n",
    "\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    Bestscores=[0,0]\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    trainX, testX,trainY,testY,validateX,validateY=prepareData()\n",
    "    for l in learning_rate:\n",
    "        for n in n_estimators:\n",
    "            for b in [0,1]:\n",
    "                for m in max_depth:\n",
    "                    for early in early_stopping_rounds:\n",
    "                        model=XGBClassifier(verbosity=0,max_depth=m,learning_rate=l,booster=booster[int(b)])\n",
    "                        model.fit(trainX,trainY,eval_set=[(testX,testY)],early_stopping_rounds=early,verbose=False)\n",
    "                        y_preds=model.predict(validateX)\n",
    "                        currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                        if(currScore>Bestscores[0]):\n",
    "                            Bestscores[0]=currScore\n",
    "                            Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])\n",
    "    forCalc.append(Bestscores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Random Seed on model\n",
    " Does changing the random seed during training but keeping the same dataset substantially change the outcome for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  24  habitable(2883,3716,3132,1604,2882,2129,2156,3741,3742,1845,151,1137,2155,2189,2316,1147,3115,1205,2014,130,1227,114,2547,2223,\b )\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "X_sm,y_sm,validateX,validateY=prepareData()\n",
    "n_neighbours=[1,2,5,7]\n",
    "algorithm=['auto','ball_tree','kd_tree','brute']\n",
    "leaf_size=[10,20,30,40]\n",
    "p=[1,2,5]\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    Bestscores=[0,0]\n",
    "    for n in n_neighbours:\n",
    "        for a in algorithm:\n",
    "            for l in leaf_size:\n",
    "                for P in p:\n",
    "                    model=KNeighborsClassifier(n_neighbors=n,algorithm=a,leaf_size=l,p=P)\n",
    "                    model.fit(X_sm,y_sm)\n",
    "                    y_preds=model.predict(validateX)\n",
    "                    currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                    if(currScore>Bestscores[0]):\n",
    "                        Bestscores[0]=currScore\n",
    "                        Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of changing random seed when preparing data on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "Hiding  24  habitable(3233,163,117,2031,2014,1845,1137,703,3716,153,3922,2883,130,128,1205,2156,2223,151,2542,1604,3133,3115,3741,2880,\b )\n",
      "BEST SCORE: 0.7869318181818181\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "Hiding  24  habitable(2014,130,3962,2882,2547,2189,2503,128,1137,1227,2883,1604,2541,3233,114,152,3132,3742,117,1424,163,1205,1845,2542,\b )\n",
      "BEST SCORE: 0.7471590909090909\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "Hiding  24  habitable(2902,1147,151,2014,2547,2135,3962,2223,1205,3233,1424,1227,114,2156,1845,986,128,3744,2441,2541,117,3741,2129,3115,\b )\n",
      "BEST SCORE: 0.7244318181818181\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "Hiding  24  habitable(151,3133,1205,2156,3962,3115,3742,2223,2129,3744,986,2316,2014,2547,1147,117,2097,3741,3132,114,2155,152,3716,1845,\b )\n",
      "BEST SCORE: 0.7471590909090909\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "Hiding  24  habitable(986,2547,2882,2031,1205,1147,2097,1227,128,2902,3233,3962,163,2021,2441,1424,1137,3744,130,2883,2135,3742,2156,3743,\b )\n",
      "BEST SCORE: 0.7386363636363636\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "n_neighbours=[1,2,5,7]\n",
    "algorithm=['auto','ball_tree','kd_tree','brute']\n",
    "leaf_size=[10,20,30,40]\n",
    "p=[1,2,5]\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    X_sm,y_sm,validateX,validateY=prepareData()\n",
    "    RandomSeed=RandomSeed+10\n",
    "    Bestscores=[0,0]\n",
    "    for n in n_neighbours:\n",
    "        for a in algorithm:\n",
    "            for l in leaf_size:\n",
    "                for P in p:\n",
    "                    model=KNeighborsClassifier(n_neighbors=n,algorithm=a,leaf_size=l,p=P)\n",
    "                    model.fit(X_sm,y_sm)\n",
    "                    y_preds=model.predict(validateX)\n",
    "                    currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                    if(currScore>Bestscores[0]):\n",
    "                        Bestscores[0]=currScore\n",
    "                        Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Random Seed on model\n",
    " Does changing the random seed during training but keeping the same dataset substantially change the outcome for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  24  habitable(2129,128,1227,3742,3606,151,3115,1845,2316,3744,1205,1424,2156,2547,3132,2902,2031,3133,2882,1604,2155,2541,986,163,\b )\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "X_sm,y_sm,validateX,validateY=prepareData()\n",
    "penalty=[None, 'l2' , 'elasticnet']\n",
    "alpha=[ 1,0.1,0.01, 0.001]\n",
    "max_iter=[500,1000,2000]\n",
    "tol=[0.00001,0.0001,0.001,0.01]\n",
    "n_iter_no_change=[10,13,20]\n",
    "eta0=[1,10,20,50,100,200]\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    Bestscores=[0,0]\n",
    "    for p in penalty:\n",
    "        for a in alpha:\n",
    "            for m in max_iter:\n",
    "                for t in tol:\n",
    "                    for e in eta0:\n",
    "                        for n in n_iter_no_change:\n",
    "                                model= Perceptron(penalty=p,alpha=a,tol=t,n_iter_no_change=n,max_iter=m,n_jobs=-1,early_stopping=True,eta0=e)\n",
    "                                model.fit(X_sm,y_sm)\n",
    "                                y_preds=model.predict(validateX)\n",
    "                                currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                                if(currScore>Bestscores[0]):\n",
    "                                    Bestscores[0]=currScore\n",
    "                                    Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of changing random seed when preparing data on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "\n",
      "TEST NUMBER 0 Random Seed = 42\n",
      "Hiding  24  habitable(3233,163,117,2031,2014,1845,1137,703,3716,153,3922,2883,130,128,1205,2156,2223,151,2542,1604,3133,3115,3741,2880,\b )\n",
      "BEST SCORE: 0.8607954545454546\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 50, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 13, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 52\n",
      "Hiding  24  habitable(2014,130,3962,2882,2547,2189,2503,128,1137,1227,2883,1604,2541,3233,114,152,3132,3742,117,1424,163,1205,1845,2542,\b )\n",
      "BEST SCORE: 0.84375\n",
      "PARAMS: {'alpha': 0.01, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 13, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 62\n",
      "Hiding  24  habitable(2902,1147,151,2014,2547,2135,3962,2223,1205,3233,1424,1227,114,2156,1845,986,128,3744,2441,2541,117,3741,2129,3115,\b )\n",
      "BEST SCORE: 0.8210227272727273\n",
      "PARAMS: {'alpha': 0.01, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 20, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 72\n",
      "Hiding  24  habitable(151,3133,1205,2156,3962,3115,3742,2223,2129,3744,986,2316,2014,2547,1147,117,2097,3741,3132,114,2155,152,3716,1845,\b )\n",
      "BEST SCORE: 0.8494318181818182\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 20, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 82\n",
      "Hiding  24  habitable(986,2547,2882,2031,1205,1147,2097,1227,128,2902,3233,3962,163,2021,2441,1424,1137,3744,130,2883,2135,3742,2156,3743,\b )\n",
      "BEST SCORE: 0.8522727272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 20, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "penalty=[None, 'l2' , 'elasticnet']\n",
    "alpha=[ 1,0.1,0.01, 0.001]\n",
    "max_iter=[500,1000,2000]\n",
    "tol=[0.00001,0.0001,0.001,0.01]\n",
    "n_iter_no_change=[10,13,20]\n",
    "eta0=[1,10,20,50,100,200]\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    X_sm,y_sm,validateX,validateY=prepareData()\n",
    "    Bestscores=[0,0]\n",
    "    for p in penalty:\n",
    "        for a in alpha:\n",
    "            for m in max_iter:\n",
    "                for t in tol:\n",
    "                    for e in eta0:\n",
    "                        for n in n_iter_no_change:\n",
    "                                model= Perceptron(penalty=p,alpha=a,tol=t,n_iter_no_change=n,max_iter=m,n_jobs=-1,early_stopping=True,eta0=e)\n",
    "                                model.fit(X_sm,y_sm)\n",
    "                                y_preds=model.predict(validateX)\n",
    "                                currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                                if(currScore>Bestscores[0]):\n",
    "                                    Bestscores[0]=currScore\n",
    "                                    Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
