{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "eaOdGH3lOe8s",
    "outputId": "670500e8-2515-4b59-b4ca-67b05b225cd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "import random as r\n",
    "from imblearn.over_sampling import SMOTE\n",
    "r.seed(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "w1DdUIVnOe83",
    "outputId": "135a1ba8-7bd9-4b3c-8d61-f50dbb475923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "exoData=pd.read_csv('../simpleImputedMiceRf')\n",
    "#These are the row_ids of exoplanets that are known to be habitable\n",
    "habitableRows=[151, 152, 153, 1604, 2155, 2223, 2882, 3133, 3606, 3716, 3742,3743, 3744]\n",
    "\n",
    "#Creates a Series that uses 1 or 0 to indicate whether a corresponding record in the exoData\n",
    "habitable=exoData.row_id.isin(habitableRows).replace(True,1).rename('habitable')\n",
    "\n",
    "#Store row ids series and remove for scaling all data to values between 0 and 1\n",
    "row_id=exoData.row_id\n",
    "data=exoData.drop('row_id',axis=1)\n",
    "scaledData=pd.DataFrame(StandardScaler().fit_transform(data),columns=data.columns)\n",
    "\n",
    "#join the scaled data columns, row_id and habitable column,into the variable preprocessed and shuffle\n",
    "preprocessed=pd.concat([row_id,scaledData,habitable],axis=1)\n",
    "preprocessed=shuffle(preprocessed,random_state=100).reset_index()\n",
    "preprocessed=preprocessed.drop('index',axis=1)   \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AOT65KLLOe9L",
    "outputId": "30d724b6-84ec-4dec-bedd-a914908dbb90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  6  habitable(3716,2223,2882,151,3743,3606,\b )\n"
     ]
    }
   ],
   "source": [
    "#List of columns to be used for training\n",
    "#it will be all columns in preprocessed except for \"habitable\" and \"row_id\"\n",
    "trainCols=[x for x in preprocessed.columns if x not in ['habitable','row_id']]\n",
    "validate=[]\n",
    "Hcopy=habitableRows.copy()\n",
    "\n",
    "#numHidden sets the number of habitable planets to use for validation of the model\n",
    "numHidden=round(len(Hcopy)/2)\n",
    "\n",
    "#Randomly select \"numHidden\" number of habitable exoplanets and\n",
    "#add their row_id to validation set \n",
    "print(\"Hiding \",numHidden,\" habitable(\",end=\"\")\n",
    "for i in range(numHidden): \n",
    "    randNum=r.randint(0,len(Hcopy)-1)\n",
    "    validate.append(Hcopy[randNum])\n",
    "    print(Hcopy[randNum],end=\",\")\n",
    "    del Hcopy[randNum]\n",
    "print(\"\\b )\")\n",
    "\n",
    "#Add row_id of non-habitable planets to the validation set till its length becomes 100\n",
    "while len(validate)<100:\n",
    "    temp=r.randint(0,3500)\n",
    "    if temp not in habitableRows:\n",
    "        validate.append(temp)\n",
    "\n",
    "#Take all columns of the planets whose row_id is in \"validate\" variable(in the validation set) and\n",
    "#store it in \"validate\" variable\n",
    "validate=preprocessed[preprocessed.row_id.isin(validate)]\n",
    "\n",
    "#Store the planets that are not in the validation set in the training set\n",
    "trainingSet=preprocessed[~preprocessed.row_id.isin(validate.row_id)]\n",
    "\n",
    "#Store the training features in X and target feature(habitable or not) in y \n",
    "X=trainingSet[trainCols]\n",
    "y=trainingSet.habitable\n",
    "\n",
    "#the SMOTE library mutates existing data to creating more data\n",
    "#Here we use SMOTE to increase the number of habitable planets in the training and validation data\n",
    "smote = SMOTE(ratio='minority')\n",
    "X_sm, y_sm = smote.fit_sample(X, y)\n",
    "validateX,validateY=smote.fit_sample(validate[trainCols],validate.habitable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "886MR46YOe-G",
    "outputId": "79364c3b-e5f6-4f36-8041-87367518eabf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<function sklearn.metrics.classification.balanced_accuracy_score>: ['balanced_accuracy_score',\n",
       "  0.8506493506493507,\n",
       "  {'C': 0.001,\n",
       "   'cache_size': 200,\n",
       "   'class_weight': None,\n",
       "   'coef0': 0,\n",
       "   'decision_function_shape': 'ovo',\n",
       "   'degree': 1,\n",
       "   'gamma': 'auto',\n",
       "   'kernel': 'linear',\n",
       "   'max_iter': -1,\n",
       "   'probability': False,\n",
       "   'random_state': None,\n",
       "   'shrinking': True,\n",
       "   'tol': 1,\n",
       "   'verbose': False}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVC TEST\n",
    "#Find the optimal hyperparameters for SVC using the following scoring meassures\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# final_model=SVC(C=0.001,coef0=0,decision_function_shape='ovo',gamma='auto',kernel='linear',max_iter=-1,shrinking=True,tol=0.001,verbose=False,random_state=n)\n",
    "#Parameters to check:\n",
    "coef=[0,0.1,0.001,0.01]\n",
    "degree=[1,2,3]\n",
    "C =[1,0.1,0.01,0.001,0.00001]\n",
    "shrink=[True,False]\n",
    "decision_shape=['ovo','ovr']\n",
    "tol=[1,0.1,0.01,0.001,0.0001]\n",
    "\n",
    "Bestscores={balanced_accuracy_score:['balanced_accuracy_score',-1,{}]}\n",
    "n=0\n",
    "#Training the data on some probable hyperparameters\n",
    "#storing the best parameters in the Bestscores dictionary\n",
    "for c in C:\n",
    "    for dec in decision_shape:\n",
    "        for d in degree:\n",
    "            for co in coef:\n",
    "                for t in tol:\n",
    "                    for s in shrink:\n",
    "                        n+=1\n",
    "                        testSvc=SVC(C=c,coef0=co,tol=t,kernel='linear',degree=d,gamma='auto',shrinking=s,decision_function_shape=dec)\n",
    "                        testSvc.fit(X_sm,y_sm)\n",
    "                        y_preds=testSvc.predict(validateX)\n",
    "                        for score_method in Bestscores:\n",
    "                            currScore=score_method(validateY,y_preds)\n",
    "                            if(currScore>Bestscores[score_method][1]):\n",
    "                                Bestscores[score_method][1]=currScore\n",
    "                                Bestscores[score_method][2]=testSvc.get_params()\n",
    "\n",
    "Bestscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Getting Feature importance:\n",
    "### I use the feature weights as the importance as larger the absolute value of the weight, larger would be its impact on the result. Perceptron has a .coef_ attribute to get feature weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "J71OwfrsIG1n",
    "outputId": "ff82060d-7270-4be0-a369-e8df11ba0b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl_controvflag 0.07001099056395808\n",
      "pl_pnum -0.02271914062498304\n",
      "pl_orbper -0.00915420179401016\n",
      "pl_orbsmax -0.018308040349642143\n",
      "pl_radj -0.014465643559427284\n",
      "pl_ttvflag -0.033993633189637315\n",
      "pl_kepflag 0.026899269714568873\n",
      "pl_k2flag -0.0026217271088529535\n",
      "ra 0.051236979812831346\n",
      "dec 0.04648636304278767\n",
      "st_dist -0.014897876820458353\n",
      "st_optmag 0.040040429386226685\n",
      "gaia_gmag 0.01918893773572667\n",
      "st_teff -0.011234710081077015\n",
      "st_mass 0.012175526413982722\n",
      "st_rad 0.0062777373625333595\n",
      "pl_tranflag -0.01771308660466241\n",
      "pl_rvflag -0.04511724232967508\n",
      "pl_imgflag -0.02683271735560755\n",
      "pl_astflag 9.107298248878237e-18\n",
      "pl_omflag -0.045123472212485874\n",
      "pl_cbflag -0.015921808193265646\n",
      "pl_angsep -0.02000683208459723\n",
      "pl_rade -0.012020116459188577\n",
      "pl_rads -0.013791093769181719\n",
      "pl_trandur 0.024604397586547422\n",
      "pl_tranmid -0.01640388859078081\n",
      "pl_ratror -0.013291728671301671\n",
      "pl_mnum 0.0\n",
      "pl_st_npar 0.053795313432173246\n",
      "pl_st_nref 0.029202086777772175\n",
      "st_rah 0.05123697933974705\n",
      "st_glon 0.015267349833853356\n",
      "st_glat -0.012950764332360446\n",
      "st_elon 0.08347846317215309\n",
      "st_elat 0.03596580389623133\n",
      "gaia_plx 0.06744907692536617\n",
      "gaia_dist -0.018744752775054954\n",
      "st_pmra 0.09897941953476457\n",
      "st_pmdec -0.015486103211225375\n",
      "st_pm 0.01710668849240206\n",
      "gaia_pmra 0.32098280396714945\n",
      "gaia_pmdec -0.1795018778081871\n",
      "gaia_pm 0.24186750870782703\n",
      "st_logg -0.07230733349996707\n",
      "st_metfe -0.025132290275651576\n",
      "st_j 0.016261702521583103\n",
      "st_h 0.020698567209685152\n",
      "st_k 0.021378541901084458\n",
      "st_wise1 0.02578830073787382\n",
      "st_wise2 0.028935215252493648\n",
      "st_wise3 0.04904886615664595\n",
      "st_wise4 -0.036119313852112526\n",
      "st_jmh2 -0.05113142546912143\n",
      "st_hmk2 -0.018002960195139868\n",
      "st_jmk2 -0.048358721702650445\n"
     ]
    }
   ],
   "source": [
    "final_model=SVC(C=0.001,coef0=0,decision_function_shape='ovo',gamma='auto',kernel='linear',max_iter=-1,shrinking=True,tol=1,verbose=False,random_state=n)\n",
    "final_model.fit(X_sm,y_sm)\n",
    "#Getting Feature weights from best model\n",
    "a=final_model.coef_\n",
    "for n in range(len(a[0])):\n",
    "    print(list(X.columns)[n],a[0][n])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SVM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
