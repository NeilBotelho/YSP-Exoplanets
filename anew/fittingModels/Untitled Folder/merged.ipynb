{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets used:\n",
    "\n",
    "1. [The NASA exoplanet archive](https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=planets)\n",
    "2. [The Planetary Habitability Laboratory (PHL) optimistic and conservative samples of potentially habitable planets]( http://phl.upr.edu/projects/habitable-exoplanets-catalog/data/database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import the data\n",
    "\n",
    "#PHL data \n",
    "hec_data = pd.read_csv(\"http://www.hpcf.upr.edu/~abel/phl/hec2/database/phl_exoplanet_catalog.csv\")\n",
    "\n",
    "#NASA exoplanets data \n",
    "!curl https://raw.githubusercontent.com/NeilBotelho/YSP-Exoplanets/master/exoplanets.csv > exoplanets.csv\n",
    "exos=pd.read_csv('exoplanets.csv')\n",
    "\n",
    "# remove unconfirmed planets\n",
    "hec_data = hec_data[hec_data.P_STATUS == 3].drop('P_STATUS', axis=\"columns\")    # P_STATUS - planet status (confirmed = 3)\n",
    "\n",
    "# leave only the habitable planets\n",
    "hec_data = hec_data[hec_data.P_HABITABLE != 0]  # P_HABITABLE - planet is potentially habitable index  (1 = conservative, 2 = optimistic)\n",
    "\n",
    "# join the data with the NASA exoplanets database to create a column that classifies if the planet is potentially habitable\n",
    "habitable_planets_names = hec_data.P_NAME.values\n",
    "exos[\"habitable\"]  = exos['pl_name'].isin(habitable_planets_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation:\n",
    "\n",
    "The NASA exoplanets archive has a significant amount of missing data, with some columns having more than 90% data missing as can be seen in the graph below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as mn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the data\n",
    "hec_data_copy = pd.read_csv(\"../../phl_exoplanet_catalog.csv\")\n",
    "exos=pd.read_csv('../../exoplanets.csv')\n",
    "imputedData=pd.read_csv('../../ImputedNumericCols.csv')\n",
    "preprocessed=pd.read_csv(\"../../PreprocessedDataset.csv\")\n",
    "\n",
    "missing={}\n",
    "for n in exos.columns:\n",
    "    missing[n]=exos[n].isnull().sum()/len(exos)\n",
    "# print(missing['gaia_pmlimmissing\n",
    "x=[x[0] for x in sorted(missing.items(), key = lambda kv:(kv[1]))]\n",
    "y=[missing[val]*100 for val in x]\n",
    "y\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(\"Sorted Columns\",fontsize=25)\n",
    "plt.ylabel(\"Missing Percentage\",fontsize=25)\n",
    "plt.title(\"Missing Data\",fontsize=40)\n",
    "fig= plt.scatter(x,y,s=25)\n",
    "fig=plt.plot(['a' for n in x],[100 for n in y])\n",
    "plt.savefig(\"missingScatterPlot.jpg\")\n",
    "\n",
    "fig=plt.figure(figsize=(60,60))\n",
    "fig=mn.matrix(exos,inline=False,sparkline=False)\n",
    "plt.ylabel(\"row number\",fontsize=40)\n",
    "plt.xlabel(\"column\",fontsize=40)\n",
    "plt.savefig(\"RawExosMatrix.jpg\")\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "fig=mn.matrix(exos[exos.columns[:int(len(exos.columns)/2)]],inline=False,sparkline=False)\n",
    "plt.ylabel(\"row number\",fontsize=40)\n",
    "plt.xlabel(\"column\",fontsize=40)\n",
    "plt.savefig(\"RawExosMatrix1.jpg\")\n",
    "\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "fig=mn.matrix(exos[exos.columns[int(len(exos.columns)/2):]],inline=False,sparkline=False)\n",
    "plt.ylabel(\"row number\",fontsize=40)\n",
    "plt.xlabel(\"column\",fontsize=40)\n",
    "plt.savefig(\"RawExosMatrix2.jpg\")\n",
    "\n",
    "# ########################################################\n",
    "# #Recreate preprocessing\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# # remove unconfirmed planets\n",
    "# hec_data = hec_data[hec_data.P_STATUS == 3].drop('P_STATUS', axis=\"columns\")    # P_STATUS - planet status (confirmed = 3)\n",
    "\n",
    "# # leave only the habitable planets\n",
    "# hec_data = hec_data[hec_data.P_HABITABLE != 0]  # P_HABITABLE - planet is potentially habitable index  (1 = conservative, 2 = optimistic)\n",
    "\n",
    "# # join the data with the NASA exoplanets database to create a column that classifies if the planet is potentially habitable\n",
    "# habitable_planets_names = hec_data.P_NAME.values\n",
    "# exos[\"habitable\"]  = exos['pl_name'].isin(habitable_planets_names)\n",
    "\n",
    "\n",
    "# #Merge the imputed data and the exoplanets dataset\n",
    "# for n in imputedData.columns:\n",
    "#     if n not in exos.columns:\n",
    "#         print(n)\n",
    "#     else:\n",
    "#         exos[n]=imputedData[n]\n",
    "\n",
    "# #These columns may introduce bias in the model so remove them\n",
    "# remove=['pl_letter', 'pl_discmethod', 'pl_nnotes', 'ra_str', 'dec_str', 'rowupdate', 'pl_tsystemref', 'pl_def_reflink', 'pl_disc', 'pl_disc_reflink', 'pl_locale', 'pl_facility', 'pl_telescope', 'pl_instrument', 'pl_status', 'pl_pelink', 'st_nts', 'st_nplc', 'st_nglc', 'st_nrvc', 'st_naxa', 'st_nimg', 'st_nspec', 'st_photn', 'st_colorn', 'pl_hostname', 'pl_name', 'ra_str', 'dec_str', 'rowupdate', 'pl_def_reflink', 'pl_disc_reflink', 'pl_pelink', 'pl_edelink', 'pl_publ_date', 'hd_name', 'hip_name', 'st_spstr', 'swasp_id']\n",
    "\n",
    "# exos=exos.drop(remove,axis=1)\n",
    "\n",
    "# # remove columns with more the 40% missing data\n",
    "# def moreThan40Missing(col):\n",
    "#         numMissing=len(exos[exos[col].isnull()])\n",
    "#         if numMissing/len(exos)>0.4:\n",
    "#                 return 1\n",
    "#         return 0\n",
    "# SignificantMissingData=[x for x in exos.columns if moreThan40Missing(x) ]\n",
    "# exos=exos.drop(SignificantMissingData,axis=1)\n",
    "\n",
    "# Cat=[x for x in exos.columns if x not in exos._get_numeric_data().columns]\n",
    "# for n in Cat:\n",
    "#     if(len(exos[n].unique())>10):\n",
    "#         exos=exos.drop(n,axis=1)\n",
    "# Cat=[x for x in exos.columns if x not in exos._get_numeric_data().columns]\n",
    "\n",
    "# #End Preprocessing recreation\n",
    "# ###################################################################\n",
    "\n",
    "\n",
    "# fig=plt.figure(figsize=(60,60))\n",
    "# fig=mn.matrix(exos,inline=False,sparkline=False)\n",
    "# plt.ylabel(\"row number\",fontsize=40)\n",
    "# plt.xlabel(\"column\",fontsize=40)\n",
    "# plt.savefig(\"ExosAfterPreparation.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data we imputed using the MICE library in R\n",
    "imputedData=pd.read_csv('../ImputedNumericCols.csv')\n",
    "\n",
    "#Merge the imputed data and the exoplanets dataset\n",
    "for n in imputedData.columns:\n",
    "    if n not in exos.columns:\n",
    "        print(n)\n",
    "    else:\n",
    "        exos[n]=imputedData[n]\n",
    "\n",
    "#These columns may introduce bias in the model so remove them\n",
    "remove=['pl_letter', 'pl_discmethod', 'pl_nnotes', 'ra_str', 'dec_str', 'rowupdate', 'pl_tsystemref', 'pl_def_reflink', 'pl_disc', 'pl_disc_reflink', 'pl_locale', 'pl_facility', 'pl_telescope', 'pl_instrument', 'pl_status', 'pl_pelink', 'st_nts', 'st_nplc', 'st_nglc', 'st_nrvc', 'st_naxa', 'st_nimg', 'st_nspec', 'st_photn', 'st_colorn', 'pl_hostname', 'pl_name', 'ra_str', 'dec_str', 'rowupdate', 'pl_def_reflink', 'pl_disc_reflink', 'pl_pelink', 'pl_edelink', 'pl_publ_date', 'hd_name', 'hip_name', 'st_spstr', 'swasp_id']\n",
    "\n",
    "exos=exos.drop(remove,axis=1)\n",
    "\n",
    "# remove columns with more the 40% missing data\n",
    "def moreThan40Missing(col):\n",
    "        numMissing=len(exos[exos[col].isnull()])\n",
    "        if numMissing/len(exos)>0.4:\n",
    "                return 1\n",
    "        return 0\n",
    "SignificantMissingData=[x for x in exos.columns if moreThan40Missing(x) ]\n",
    "exos=exos.drop(SignificantMissingData,axis=1)\n",
    "\n",
    "Cat=[x for x in exos.columns if x not in exos._get_numeric_data().columns]\n",
    "for n in Cat:\n",
    "    if(len(exos[n].unique())>10):\n",
    "        exos=exos.drop(n,axis=1)\n",
    "Cat=[x for x in exos.columns if x not in exos._get_numeric_data().columns]\n",
    "\n",
    "#Fill missing values with np.nan or \"Missing\"(if categorical)\n",
    "for n in exos.columns:\n",
    "    if(n in Cat):\n",
    "        exos[n]=pd.Categorical(exos[n])\n",
    "        exos[n]=exos[n].cat.add_categories(\"Missing\").fillna(\"Missing\")\n",
    "    else:\n",
    "        exos[n]=exos[n].fillna(np.nan)\n",
    "exos=exos.set_index(\"rowid\")\n",
    "\n",
    "#Now we use a simple imputer to impute the remaining missing data.\n",
    "#Simple imputers only work on numerical data so we only extract the numerical data from the exoplanets dataset\n",
    "#Separate the habitable planets data from the dataset and impute the resulting two datasets using median imputation\n",
    "habitable=exos[exos.habitable==True]\n",
    "nonHabitable=exos[~exos.habitable==True]\n",
    "\n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "habitable[habitable._get_numeric_data().columns]=imputer.fit_transform(habitable[habitable._get_numeric_data().columns])\n",
    "nonHabitable[nonHabitable._get_numeric_data().columns]=imputer.fit_transform(nonHabitable[nonHabitable._get_numeric_data().columns])\n",
    "\n",
    "\n",
    "# Join the two datasets\n",
    "tempExos=pd.concat([habitable,nonHabitable])\n",
    "\n",
    "for n in tempExos.columns:\n",
    "    if(n in exos.columns):\n",
    "        exos[n]=tempExos[n]\n",
    "    else:\n",
    "        print(n)\n",
    "#Scale the data so that it has unit variance\n",
    "NumericCols=[]\n",
    "for n in exos._get_numeric_data().columns:\n",
    "\t#Dont  scale binary columns(ie those that only have 1 or 0)\n",
    "    if not (list(exos[n].unique())==[0,1]):\n",
    "        NumericCols.append(n)\n",
    "exos[NumericCols]=StandardScaler().fit_transform(exos[NumericCols])\n",
    "\n",
    "#One hot encode categorical columns\n",
    "preprocessed=pd.get_dummies(exos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random as r\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "preprocessed=pd.read_csv(\"../PreprocessedDataset.csv\")\n",
    "habitableRows=list(preprocessed.rowid[preprocessed.habitable==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData():\n",
    "    #List of columns to be used for training\n",
    "    #it will be all columns in preprocessed except for \"habitable\" and \"rowid\"\n",
    "    trainCols=[x for x in preprocessed.columns if x not in ['habitable','rowid']]\n",
    "    validate=[]\n",
    "    Hcopy=habitableRows.copy()\n",
    "    #numHidden sets the number of habitable planets to use for validation of the model\n",
    "    numHidden=round(len(Hcopy)/2)\n",
    "\n",
    "    #Randomly select habitable exoplanets and \n",
    "    #add their row_id to validation set \n",
    "    print(\"Hiding \",numHidden,\" habitable(\",end=\"\")\n",
    "    for i in range(numHidden): \n",
    "        randNum=r.randint(0,len(Hcopy)-1)  \n",
    "        validate.append(Hcopy[randNum])\n",
    "        print(Hcopy[randNum],end=\",\")\n",
    "        del Hcopy[randNum]\n",
    "    print(\"\\b )\")\n",
    "\n",
    "    #Add row_id of non-habitable planets to the validation set till its length becomes 200\n",
    "    while len(validate)<200:\n",
    "        temp=r.randint(0,len(preprocessed)-1)\n",
    "        if temp not in habitableRows and temp not in validate:\n",
    "            validate.append(temp)\n",
    "\n",
    "    #Take all columns of the planets whose row_id is in \"validate\" variable(in the validation set) and\n",
    "    #store it in \"validate\" variable\n",
    "    validate=preprocessed[preprocessed.rowid.isin(validate)]\n",
    "\n",
    "    #Store the planets that are not in the validation set in the training set\n",
    "    trainingSet=preprocessed[~preprocessed.rowid.isin(validate.rowid)]\n",
    "\n",
    "    #Store the training features in X and target feature(habitable or not) in y \n",
    "    X=trainingSet[trainCols]\n",
    "    y=trainingSet.habitable\n",
    "\n",
    "    #the SMOTE library mutates existing data to creating more data\n",
    "    #Here we use SMOTE to increase the number of habitable planets in the training and validation data\n",
    "    smote = SMOTE(ratio='minority')\n",
    "    X_sm, y_sm = smote.fit_sample(X, y)\n",
    "    trainX, testX,trainY,testY=train_test_split(X_sm,y_sm)\n",
    "    validateX,validateY=smote.fit_sample(validate[trainCols],validate.habitable)\n",
    "    return trainX, testX,trainY,testY,validateX,validateY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Random Seed on model\n",
    " Does changing the random seed during training but keeping the same dataset substantially change the outcome for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  24  habitable(128,2189,2316,2547,986,117,1424,1845,3115,3606,2097,2441,1205,3962,2031,153,2882,152,3743,1147,2902,2156,2883,2155,\b )\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "BEST SCORE: 0.9261363636363635\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "Bestscores=[0,0]\n",
    "trainX, testX,trainY,testY,validateX,validateY=prepareData()\n",
    "\n",
    "max_depth=[3,5,7,10]\n",
    "learning_rate=[1,0.1,0.01,0.001]\n",
    "n_estimators=[10,50,100,150,200]\n",
    "early_stopping_rounds=[3,5,10,20]\n",
    "booster=[\"gbtree\",\"dart\"]\n",
    "n_jobs=-1\n",
    "loss_function=['Logloss','CrossEntropy','MultiClass', 'MultiClassOneVsAll' ]\n",
    "\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    Bestscores=[0,0]\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    for l in learning_rate:\n",
    "        for n in n_estimators:\n",
    "            for b in [0,1]:\n",
    "                for m in max_depth:\n",
    "                    for early in early_stopping_rounds:\n",
    "                        model=XGBClassifier(verbosity=0,max_depth=m,learning_rate=l,booster=booster[int(b)])\n",
    "                        model.fit(trainX,trainY,eval_set=[(testX,testY)],early_stopping_rounds=early,verbose=False)\n",
    "                        y_preds=model.predict(validateX)\n",
    "                        currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                        if(currScore>Bestscores[0]):\n",
    "                            Bestscores[0]=currScore\n",
    "                            Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of changing random seed when preparing data on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "Hiding  24  habitable(3233,163,117,2031,2014,1845,1137,703,3716,153,3922,2883,130,128,1205,2156,2223,151,2542,1604,3133,3115,3741,2880,\b )\n",
      "BEST SCORE: 0.9772727272727273\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "Hiding  24  habitable(2014,130,3962,2882,2547,2189,2503,128,1137,1227,2883,1604,2541,3233,114,152,3132,3742,117,1424,163,1205,1845,2542,\b )\n",
      "BEST SCORE: 0.9346590909090909\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "Hiding  24  habitable(2902,1147,151,2014,2547,2135,3962,2223,1205,3233,1424,1227,114,2156,1845,986,128,3744,2441,2541,117,3741,2129,3115,\b )\n",
      "BEST SCORE: 0.7897727272727273\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "Hiding  24  habitable(151,3133,1205,2156,3962,3115,3742,2223,2129,3744,986,2316,2014,2547,1147,117,2097,3741,3132,114,2155,152,3716,1845,\b )\n",
      "BEST SCORE: 0.9630681818181819\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "Hiding  24  habitable(986,2547,2882,2031,1205,1147,2097,1227,128,2902,3233,3962,163,2021,2441,1424,1137,3744,130,2883,2135,3742,2156,3743,\b )\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 0}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "Bestscores=[0,0]\n",
    "forCalc=[]\n",
    "max_depth=[3,5,7,10]\n",
    "learning_rate=[1,0.1,0.01,0.001]\n",
    "n_estimators=[10,50,100,150,200]\n",
    "early_stopping_rounds=[3,5,10,20]\n",
    "booster=[\"gbtree\",\"dart\"]\n",
    "n_jobs=-1\n",
    "loss_function=['Logloss','CrossEntropy','MultiClass', 'MultiClassOneVsAll' ]\n",
    "\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    Bestscores=[0,0]\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    trainX, testX,trainY,testY,validateX,validateY=prepareData()\n",
    "    for l in learning_rate:\n",
    "        for n in n_estimators:\n",
    "            for b in [0,1]:\n",
    "                for m in max_depth:\n",
    "                    for early in early_stopping_rounds:\n",
    "                        model=XGBClassifier(verbosity=0,max_depth=m,learning_rate=l,booster=booster[int(b)])\n",
    "                        model.fit(trainX,trainY,eval_set=[(testX,testY)],early_stopping_rounds=early,verbose=False)\n",
    "                        y_preds=model.predict(validateX)\n",
    "                        currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                        if(currScore>Bestscores[0]):\n",
    "                            Bestscores[0]=currScore\n",
    "                            Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])\n",
    "    forCalc.append(Bestscores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Random Seed on model\n",
    " Does changing the random seed during training but keeping the same dataset substantially change the outcome for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  24  habitable(2883,3716,3132,1604,2882,2129,2156,3741,3742,1845,151,1137,2155,2189,2316,1147,3115,1205,2014,130,1227,114,2547,2223,\b )\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "BEST SCORE: 0.8039772727272727\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "X_sm,y_sm,validateX,validateY=prepareData()\n",
    "n_neighbours=[1,2,5,7]\n",
    "algorithm=['auto','ball_tree','kd_tree','brute']\n",
    "leaf_size=[10,20,30,40]\n",
    "p=[1,2,5]\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    Bestscores=[0,0]\n",
    "    for n in n_neighbours:\n",
    "        for a in algorithm:\n",
    "            for l in leaf_size:\n",
    "                for P in p:\n",
    "                    model=KNeighborsClassifier(n_neighbors=n,algorithm=a,leaf_size=l,p=P)\n",
    "                    model.fit(X_sm,y_sm)\n",
    "                    y_preds=model.predict(validateX)\n",
    "                    currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                    if(currScore>Bestscores[0]):\n",
    "                        Bestscores[0]=currScore\n",
    "                        Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of changing random seed when preparing data on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "Hiding  24  habitable(3233,163,117,2031,2014,1845,1137,703,3716,153,3922,2883,130,128,1205,2156,2223,151,2542,1604,3133,3115,3741,2880,\b )\n",
      "BEST SCORE: 0.7869318181818181\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "Hiding  24  habitable(2014,130,3962,2882,2547,2189,2503,128,1137,1227,2883,1604,2541,3233,114,152,3132,3742,117,1424,163,1205,1845,2542,\b )\n",
      "BEST SCORE: 0.7471590909090909\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "Hiding  24  habitable(2902,1147,151,2014,2547,2135,3962,2223,1205,3233,1424,1227,114,2156,1845,986,128,3744,2441,2541,117,3741,2129,3115,\b )\n",
      "BEST SCORE: 0.7244318181818181\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "Hiding  24  habitable(151,3133,1205,2156,3962,3115,3742,2223,2129,3744,986,2316,2014,2547,1147,117,2097,3741,3132,114,2155,152,3716,1845,\b )\n",
      "BEST SCORE: 0.7471590909090909\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 5, 'weights': 'uniform'}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "Hiding  24  habitable(986,2547,2882,2031,1205,1147,2097,1227,128,2902,3233,3962,163,2021,2441,1424,1137,3744,130,2883,2135,3742,2156,3743,\b )\n",
      "BEST SCORE: 0.7386363636363636\n",
      "PARAMS: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 7, 'p': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "n_neighbours=[1,2,5,7]\n",
    "algorithm=['auto','ball_tree','kd_tree','brute']\n",
    "leaf_size=[10,20,30,40]\n",
    "p=[1,2,5]\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    X_sm,y_sm,validateX,validateY=prepareData()\n",
    "    RandomSeed=RandomSeed+10\n",
    "    Bestscores=[0,0]\n",
    "    for n in n_neighbours:\n",
    "        for a in algorithm:\n",
    "            for l in leaf_size:\n",
    "                for P in p:\n",
    "                    model=KNeighborsClassifier(n_neighbors=n,algorithm=a,leaf_size=l,p=P)\n",
    "                    model.fit(X_sm,y_sm)\n",
    "                    y_preds=model.predict(validateX)\n",
    "                    currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                    if(currScore>Bestscores[0]):\n",
    "                        Bestscores[0]=currScore\n",
    "                        Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Random Seed on model\n",
    " Does changing the random seed during training but keeping the same dataset substantially change the outcome for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  24  habitable(2129,128,1227,3742,3606,151,3115,1845,2316,3744,1205,1424,2156,2547,3132,2902,2031,3133,2882,1604,2155,2541,986,163,\b )\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "BEST SCORE: 0.8835227272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 10, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "X_sm,y_sm,validateX,validateY=prepareData()\n",
    "penalty=[None, 'l2' , 'elasticnet']\n",
    "alpha=[ 1,0.1,0.01, 0.001]\n",
    "max_iter=[500,1000,2000]\n",
    "tol=[0.00001,0.0001,0.001,0.01]\n",
    "n_iter_no_change=[10,13,20]\n",
    "eta0=[1,10,20,50,100,200]\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    Bestscores=[0,0]\n",
    "    for p in penalty:\n",
    "        for a in alpha:\n",
    "            for m in max_iter:\n",
    "                for t in tol:\n",
    "                    for e in eta0:\n",
    "                        for n in n_iter_no_change:\n",
    "                                model= Perceptron(penalty=p,alpha=a,tol=t,n_iter_no_change=n,max_iter=m,n_jobs=-1,early_stopping=True,eta0=e)\n",
    "                                model.fit(X_sm,y_sm)\n",
    "                                y_preds=model.predict(validateX)\n",
    "                                currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                                if(currScore>Bestscores[0]):\n",
    "                                    Bestscores[0]=currScore\n",
    "                                    Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of changing random seed when preparing data on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "\n",
      "TEST NUMBER 0 Random Seed = 42\n",
      "Hiding  24  habitable(3233,163,117,2031,2014,1845,1137,703,3716,153,3922,2883,130,128,1205,2156,2223,151,2542,1604,3133,3115,3741,2880,\b )\n",
      "BEST SCORE: 0.8607954545454546\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 50, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 13, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 52\n",
      "Hiding  24  habitable(2014,130,3962,2882,2547,2189,2503,128,1137,1227,2883,1604,2541,3233,114,152,3132,3742,117,1424,163,1205,1845,2542,\b )\n",
      "BEST SCORE: 0.84375\n",
      "PARAMS: {'alpha': 0.01, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 13, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 62\n",
      "Hiding  24  habitable(2902,1147,151,2014,2547,2135,3962,2223,1205,3233,1424,1227,114,2156,1845,986,128,3744,2441,2541,117,3741,2129,3115,\b )\n",
      "BEST SCORE: 0.8210227272727273\n",
      "PARAMS: {'alpha': 0.01, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 20, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 72\n",
      "Hiding  24  habitable(151,3133,1205,2156,3962,3115,3742,2223,2129,3744,986,2316,2014,2547,1147,117,2097,3741,3132,114,2155,152,3716,1845,\b )\n",
      "BEST SCORE: 0.8494318181818182\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 20, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 82\n",
      "Hiding  24  habitable(986,2547,2882,2031,1205,1147,2097,1227,128,2902,3233,3962,163,2021,2441,1424,1137,3744,130,2883,2135,3742,2156,3743,\b )\n",
      "BEST SCORE: 0.8522727272727273\n",
      "PARAMS: {'alpha': 0.001, 'class_weight': None, 'early_stopping': True, 'eta0': 1, 'fit_intercept': True, 'max_iter': 500, 'n_iter_no_change': 20, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 0, 'shuffle': True, 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "penalty=[None, 'l2' , 'elasticnet']\n",
    "alpha=[ 1,0.1,0.01, 0.001]\n",
    "max_iter=[500,1000,2000]\n",
    "tol=[0.00001,0.0001,0.001,0.01]\n",
    "n_iter_no_change=[10,13,20]\n",
    "eta0=[1,10,20,50,100,200]\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    X_sm,y_sm,validateX,validateY=prepareData()\n",
    "    Bestscores=[0,0]\n",
    "    for p in penalty:\n",
    "        for a in alpha:\n",
    "            for m in max_iter:\n",
    "                for t in tol:\n",
    "                    for e in eta0:\n",
    "                        for n in n_iter_no_change:\n",
    "                                model= Perceptron(penalty=p,alpha=a,tol=t,n_iter_no_change=n,max_iter=m,n_jobs=-1,early_stopping=True,eta0=e)\n",
    "                                model.fit(X_sm,y_sm)\n",
    "                                y_preds=model.predict(validateX)\n",
    "                                currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                                if(currScore>Bestscores[0]):\n",
    "                                    Bestscores[0]=currScore\n",
    "                                    Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Random Seed on model\n",
    " Does changing the random seed during training but keeping the same dataset substantially change the outcome for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  24  habitable(2135,2156,703,2503,3606,117,2155,2031,2547,128,1604,986,1205,3922,2223,2883,2014,3743,152,114,130,1227,2882,1137,\b )\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "BEST SCORE: 0.7556818181818181\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 1, 'verbose': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "BEST SCORE: 0.7556818181818181\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 1, 'verbose': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "BEST SCORE: 0.7556818181818181\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 1, 'verbose': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "BEST SCORE: 0.7556818181818181\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 1, 'verbose': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "BEST SCORE: 0.7556818181818181\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 1, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "X_sm,y_sm,validateX,validateY=prepareData()\n",
    "coef=[0,0.1,0.01,0.001]\n",
    "degree=[1,2,3]\n",
    "C =[1,0.1,0.01,0.001]\n",
    "shrink=[True,False]\n",
    "decision_shape=['ovo','ovr']\n",
    "tol=[1,0.1,0.01,0.001]\n",
    "\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    Bestscores=[0,0]\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    for c in C:\n",
    "        for dec in decision_shape:\n",
    "            for d in degree:\n",
    "                for co in coef:\n",
    "                    for t in tol:\n",
    "                        for s in shrink:\n",
    "                            model=SVC(C=c,coef0=co,tol=t,kernel='linear',degree=d,gamma='auto',shrinking=s,decision_function_shape=dec)\n",
    "                            model.fit(X_sm,y_sm)\n",
    "                            y_preds=model.predict(validateX)\n",
    "                            currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                            if(currScore>Bestscores[0]):\n",
    "                                Bestscores[0]=currScore\n",
    "                                Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])                            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of changing random seed when preparing data on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "Hiding  24  habitable(3233,163,117,2031,2014,1845,1137,703,3716,153,3922,2883,130,128,1205,2156,2223,151,2542,1604,3133,3115,3741,2880,\b )\n",
      "BEST SCORE: 0.8238636363636364\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': False, 'tol': 0.1, 'verbose': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "Hiding  24  habitable(2014,130,3962,2882,2547,2189,2503,128,1137,1227,2883,1604,2541,3233,114,152,3132,3742,117,1424,163,1205,1845,2542,\b )\n",
      "BEST SCORE: 0.8238636363636364\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': False, 'tol': 0.1, 'verbose': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "Hiding  24  habitable(2902,1147,151,2014,2547,2135,3962,2223,1205,3233,1424,1227,114,2156,1845,986,128,3744,2441,2541,117,3741,2129,3115,\b )\n",
      "BEST SCORE: 0.84375\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 1, 'verbose': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "Hiding  24  habitable(151,3133,1205,2156,3962,3115,3742,2223,2129,3744,986,2316,2014,2547,1147,117,2097,3741,3132,114,2155,152,3716,1845,\b )\n",
      "BEST SCORE: 0.84375\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 1, 'verbose': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "Hiding  24  habitable(986,2547,2882,2031,1205,1147,2097,1227,128,2902,3233,3962,163,2021,2441,1424,1137,3744,130,2883,2135,3742,2156,3743,\b )\n",
      "BEST SCORE: 0.84375\n",
      "PARAMS: {'C': 0.001, 'cache_size': 200, 'class_weight': None, 'coef0': 0, 'decision_function_shape': 'ovo', 'degree': 1, 'gamma': 'auto', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 1, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "Bestscores=[0,0]\n",
    "coef=[0,0.1,0.01,0.001]\n",
    "degree=[1,2,3]\n",
    "C =[1,0.1,0.01,0.001]\n",
    "shrink=[True,False]\n",
    "decision_shape=['ovo','ovr']\n",
    "tol=[1,0.1,0.01,0.001]\n",
    "\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    X_sm,y_sm,validateX,validateY=prepareData()\n",
    "    for c in C:\n",
    "        for dec in decision_shape:\n",
    "            for d in degree:\n",
    "                for co in coef:\n",
    "                    for t in tol:\n",
    "                        for s in shrink:\n",
    "                            model=SVC(C=c,coef0=co,tol=t,kernel='linear',degree=d,gamma='auto',shrinking=s,decision_function_shape=dec)\n",
    "                            model.fit(X_sm,y_sm)\n",
    "                            y_preds=model.predict(validateX)\n",
    "                            currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                            if(currScore>Bestscores[0]):\n",
    "                                Bestscores[0]=currScore\n",
    "                                Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])                            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Random Seed on model\n",
    " Does changing the random seed during training but keeping the same dataset substantially change the outcome for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding  24  habitable(3716,3233,2542,3115,2902,3133,3744,152,2223,3132,2547,2189,2503,986,1205,163,3606,1137,1227,2135,703,153,2541,2882,\b )\n",
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "BEST SCORE: 0.9090909090909092\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 7, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "BEST SCORE: 0.9204545454545454\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 5, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "BEST SCORE: 0.8977272727272727\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 7, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 8, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "BEST SCORE: 0.8948863636363636\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 11, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "BEST SCORE: 0.9119318181818181\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 5, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "X_sm,y_sm,validateX,validateY=prepareData()\n",
    "estimators=[x for x in range(1,100)]\n",
    "criterion=['gini','entropy']\n",
    "max_depth=[6,7,8,9]\n",
    "\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    Bestscores=[0,0]\n",
    "    for e in estimators:\n",
    "        for c in criterion:\n",
    "            for m in max_depth:\n",
    "                    model=RandomForestClassifier(n_estimators=e,max_depth=m,criterion=c,n_jobs=-1)\n",
    "                    model.fit(X_sm,y_sm)\n",
    "                    y_preds=model.predict(validateX)\n",
    "                    currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                    if(currScore>Bestscores[0]):\n",
    "                        Bestscores[0]=currScore\n",
    "                        Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of changing random seed when preparing data on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "\n",
      "TEST NUMBER 1 Random Seed = 42\n",
      "Hiding  24  habitable(3233,163,117,2031,2014,1845,1137,703,3716,153,3922,2883,130,128,1205,2156,2223,151,2542,1604,3133,3115,3741,2880,\b )\n",
      "BEST SCORE: 0.9772727272727273\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 15, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 2 Random Seed = 52\n",
      "Hiding  24  habitable(2014,130,3962,2882,2547,2189,2503,128,1137,1227,2883,1604,2541,3233,114,152,3132,3742,117,1424,163,1205,1845,2542,\b )\n",
      "BEST SCORE: 0.9005681818181818\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 43, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 3 Random Seed = 62\n",
      "Hiding  24  habitable(2902,1147,151,2014,2547,2135,3962,2223,1205,3233,1424,1227,114,2156,1845,986,128,3744,2441,2541,117,3741,2129,3115,\b )\n",
      "BEST SCORE: 0.8806818181818181\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 8, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 4 Random Seed = 72\n",
      "Hiding  24  habitable(151,3133,1205,2156,3962,3115,3742,2223,2129,3744,986,2316,2014,2547,1147,117,2097,3741,3132,114,2155,152,3716,1845,\b )\n",
      "BEST SCORE: 0.9005681818181819\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 66, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "**********\n",
      "\n",
      "TEST NUMBER 5 Random Seed = 82\n",
      "Hiding  24  habitable(986,2547,2882,2031,1205,1147,2097,1227,128,2902,3233,3962,163,2021,2441,1424,1137,3744,130,2883,2135,3742,2156,3743,\b )\n",
      "BEST SCORE: 0.7897727272727273\n",
      "PARAMS: {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 6, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "RandomSeed=42\n",
    "estimators=[x for x in range(1,100)]\n",
    "criterion=['gini','entropy']\n",
    "max_depth=[6,7,8,9]\n",
    "\n",
    "for testNumber in range(5):\n",
    "    print(\"*\"*10,end=\"\\n\\n\")\n",
    "    print(\"TEST NUMBER\",testNumber+1,\"Random Seed =\",RandomSeed)\n",
    "    r.seed(RandomSeed)\n",
    "    RandomSeed=RandomSeed+10\n",
    "    X_sm,y_sm,validateX,validateY=prepareData()\n",
    "    Bestscores=[0,0]\n",
    "    for e in estimators:\n",
    "        for c in criterion:\n",
    "            for m in max_depth:\n",
    "                    model=RandomForestClassifier(n_estimators=e,max_depth=m,criterion=c,n_jobs=-1)\n",
    "                    model.fit(X_sm,y_sm)\n",
    "                    y_preds=model.predict(validateX)\n",
    "                    currScore=balanced_accuracy_score(validateY,y_preds)\n",
    "                    if(currScore>Bestscores[0]):\n",
    "                        Bestscores[0]=currScore\n",
    "                        Bestscores[1]=model.get_params()\n",
    "    print(\"BEST SCORE:\",str(Bestscores[0])+\"\\n\"+\"PARAMS:\",Bestscores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
